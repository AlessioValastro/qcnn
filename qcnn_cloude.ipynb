{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c2c9e6c1",
      "metadata": {
        "id": "c2c9e6c1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1b0a7a01",
      "metadata": {
        "id": "1b0a7a01"
      },
      "outputs": [],
      "source": [
        "# Trasformazioni con data augmentation leggera\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c7a0c7d8",
      "metadata": {
        "id": "c7a0c7d8"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# QUATERNION OPERATION\n",
        "# =============================================================================\n",
        "\n",
        "def quaternion_conv(q_input, q_weight, bias=None, stride=1, padding=0, dilation=1, groups=1):\n",
        "    \"\"\"\n",
        "    Quaternion convolution operation\n",
        "    q_input: [batch, 4*in_channels, height, width] - quaternion input (r,i,j,k)\n",
        "    q_weight: [4*out_channels, in_channels, kernel_h, kernel_w] - quaternion weights\n",
        "    \"\"\"\n",
        "    batch_size, in_ch_4, height, width = q_input.shape\n",
        "    out_ch_4, in_ch, kernel_h, kernel_w = q_weight.shape\n",
        "\n",
        "    in_channels = in_ch_4 // 4\n",
        "    out_channels = out_ch_4 // 4\n",
        "\n",
        "    # Split input into r, i, j, k components\n",
        "    r_input = q_input[:, :in_channels]\n",
        "    i_input = q_input[:, in_channels:2*in_channels]\n",
        "    j_input = q_input[:, 2*in_channels:3*in_channels]\n",
        "    k_input = q_input[:, 3*in_channels:]\n",
        "\n",
        "    # Split weights into r, i, j, k components\n",
        "    r_weight = q_weight[:out_channels]\n",
        "    i_weight = q_weight[out_channels:2*out_channels]\n",
        "    j_weight = q_weight[2*out_channels:3*out_channels]\n",
        "    k_weight = q_weight[3*out_channels:]\n",
        "\n",
        "    # Quaternion multiplication: (a + bi + cj + dk)(e + fi + gj + hk)\n",
        "    # Result = (ae - bf - cg - dh) + (af + be + ch - dg)i + (ag - bh + ce + df)j + (ah + bg - cf + de)k\n",
        "\n",
        "    # Real part: ae - bf - cg - dh\n",
        "    rr = F.conv2d(r_input, r_weight, None, stride, padding, dilation, groups)\n",
        "    ii = F.conv2d(i_input, i_weight, None, stride, padding, dilation, groups)\n",
        "    jj = F.conv2d(j_input, j_weight, None, stride, padding, dilation, groups)\n",
        "    kk = F.conv2d(k_input, k_weight, None, stride, padding, dilation, groups)\n",
        "\n",
        "    # i component: af + be + ch - dg\n",
        "    ri = F.conv2d(r_input, i_weight, None, stride, padding, dilation, groups)\n",
        "    ir = F.conv2d(i_input, r_weight, None, stride, padding, dilation, groups)\n",
        "    jk = F.conv2d(j_input, k_weight, None, stride, padding, dilation, groups)\n",
        "    kj = F.conv2d(k_input, j_weight, None, stride, padding, dilation, groups)\n",
        "\n",
        "    # j component: ag - bh + ce + df\n",
        "    rj = F.conv2d(r_input, j_weight, None, stride, padding, dilation, groups)\n",
        "    ik = F.conv2d(i_input, k_weight, None, stride, padding, dilation, groups)\n",
        "    jr = F.conv2d(j_input, r_weight, None, stride, padding, dilation, groups)\n",
        "    ki = F.conv2d(k_input, i_weight, None, stride, padding, dilation, groups)\n",
        "\n",
        "    # k component: ah + bg - cf + de\n",
        "    rk = F.conv2d(r_input, k_weight, None, stride, padding, dilation, groups)\n",
        "    ij = F.conv2d(i_input, j_weight, None, stride, padding, dilation, groups)\n",
        "    ji = F.conv2d(j_input, i_weight, None, stride, padding, dilation, groups)\n",
        "    kr = F.conv2d(k_input, r_weight, None, stride, padding, dilation, groups)\n",
        "\n",
        "    # Combine results\n",
        "    output_r = rr - ii - jj - kk\n",
        "    output_i = ri + ir + jk - kj\n",
        "    output_j = rj - ik + jr + ki\n",
        "    output_k = rk + ij - ji + kr\n",
        "\n",
        "    # Add bias if provided\n",
        "    if bias is not None:\n",
        "        bias_r = bias[:out_channels].view(1, -1, 1, 1)\n",
        "        bias_i = bias[out_channels:2*out_channels].view(1, -1, 1, 1)\n",
        "        bias_j = bias[2*out_channels:3*out_channels].view(1, -1, 1, 1)\n",
        "        bias_k = bias[3*out_channels:].view(1, -1, 1, 1)\n",
        "\n",
        "        output_r += bias_r\n",
        "        output_i += bias_i\n",
        "        output_j += bias_j\n",
        "        output_k += bias_k\n",
        "\n",
        "    # Concatenate all components\n",
        "    output = torch.cat([output_r, output_i, output_j, output_k], dim=1)\n",
        "    return output\n",
        "\n",
        "def quaternion_init(weight, gain=1.0):\n",
        "    \"\"\"\n",
        "    Inizializza un tensor quaternion della stessa shape di weight.\n",
        "    weight: [4*out_features, in_features] oppure [4*out_channels, in_channels, kh, kw]\n",
        "    \"\"\"\n",
        "    shape = weight.shape\n",
        "    if len(shape) == 2:  # Linear\n",
        "        out_features_4, in_features = shape\n",
        "        out_features = out_features_4 // 4\n",
        "        v_r = torch.randn(out_features, in_features)\n",
        "        v_i = torch.randn(out_features, in_features)\n",
        "        v_j = torch.randn(out_features, in_features)\n",
        "        v_k = torch.randn(out_features, in_features)\n",
        "        # Normalizza\n",
        "        norm = torch.sqrt(v_r**2 + v_i**2 + v_j**2 + v_k**2) + 1e-8\n",
        "        v_r = gain * v_r / norm\n",
        "        v_i = gain * v_i / norm\n",
        "        v_j = gain * v_j / norm\n",
        "        v_k = gain * v_k / norm\n",
        "        # Concatenazione\n",
        "        w = torch.cat([v_r, v_i, v_j, v_k], dim=0)\n",
        "        return w\n",
        "    elif len(shape) == 4:  # Conv\n",
        "        out_channels_4, in_channels, kh, kw = shape\n",
        "        out_channels = out_channels_4 // 4\n",
        "        v_r = torch.randn(out_channels, in_channels, kh, kw)\n",
        "        v_i = torch.randn(out_channels, in_channels, kh, kw)\n",
        "        v_j = torch.randn(out_channels, in_channels, kh, kw)\n",
        "        v_k = torch.randn(out_channels, in_channels, kh, kw)\n",
        "        norm = torch.sqrt(v_r**2 + v_i**2 + v_j**2 + v_k**2) + 1e-8\n",
        "        v_r = gain * v_r / norm\n",
        "        v_i = gain * v_i / norm\n",
        "        v_j = gain * v_j / norm\n",
        "        v_k = gain * v_k / norm\n",
        "        w = torch.cat([v_r, v_i, v_j, v_k], dim=0)\n",
        "        return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3af8dd9a",
      "metadata": {
        "id": "3af8dd9a"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# QUATERNION LAYERS\n",
        "# =============================================================================\n",
        "\n",
        "class QuaternionConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(QuaternionConv2d, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "\n",
        "        # Quaternion weights: [4*out_channels, in_channels, kernel_h, kernel_w]\n",
        "        self.weight = nn.Parameter(torch.empty(4 * out_channels, in_channels,\n",
        "                                              self.kernel_size[0], self.kernel_size[1]))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.empty(4 * out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialize with quaternion initialization\n",
        "        with torch.no_grad():\n",
        "            self.weight.copy_(quaternion_init(self.weight))\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return quaternion_conv(input, self.weight, self.bias, self.stride,\n",
        "                             self.padding, self.dilation, self.groups)\n",
        "\n",
        "class QuaternionLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(QuaternionLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Peso: 4*output x input (quaternioni gestiti internamente)\n",
        "        self.weight = nn.Parameter(torch.empty(4 * out_features, in_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.empty(4 * out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        with torch.no_grad():\n",
        "            self.weight.copy_(quaternion_init(self.weight))\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        in_features = self.in_features\n",
        "        out_features = self.out_features\n",
        "\n",
        "        # Split input in quaternion components\n",
        "        r_input = x[:, :in_features]\n",
        "        i_input = x[:, in_features:2*in_features]\n",
        "        j_input = x[:, 2*in_features:3*in_features]\n",
        "        k_input = x[:, 3*in_features:]\n",
        "\n",
        "        # Split weights\n",
        "        r_weight = self.weight[:out_features, :]\n",
        "        i_weight = self.weight[out_features:2*out_features, :]\n",
        "        j_weight = self.weight[2*out_features:3*out_features, :]\n",
        "        k_weight = self.weight[3*out_features:, :]\n",
        "\n",
        "        # Moltiplicazione quaternion\n",
        "        output_r = (torch.mm(r_input, r_weight.t()) - torch.mm(i_input, i_weight.t()) -\n",
        "                    torch.mm(j_input, j_weight.t()) - torch.mm(k_input, k_weight.t()))\n",
        "\n",
        "        output_i = (torch.mm(r_input, i_weight.t()) + torch.mm(i_input, r_weight.t()) +\n",
        "                    torch.mm(j_input, k_weight.t()) - torch.mm(k_input, j_weight.t()))\n",
        "\n",
        "        output_j = (torch.mm(r_input, j_weight.t()) - torch.mm(i_input, k_weight.t()) +\n",
        "                    torch.mm(j_input, r_weight.t()) + torch.mm(k_input, i_weight.t()))\n",
        "\n",
        "        output_k = (torch.mm(r_input, k_weight.t()) + torch.mm(i_input, j_weight.t()) -\n",
        "                    torch.mm(j_input, i_weight.t()) + torch.mm(k_input, r_weight.t()))\n",
        "\n",
        "        output = torch.cat([output_r, output_i, output_j, output_k], dim=1)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            output += self.bias\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2c408655",
      "metadata": {
        "id": "2c408655"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# QUATERNION ACTIVATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def quaternion_relu(input):\n",
        "    \"\"\"Apply ReLU to each quaternion component\"\"\"\n",
        "    return F.relu(input)\n",
        "\n",
        "def quaternion_split_relu(input):\n",
        "    \"\"\"Alternative quaternion ReLU that preserves quaternion structure\"\"\"\n",
        "    batch_size, channels = input.shape[0], input.shape[1] // 4\n",
        "\n",
        "    # Split into components\n",
        "    r, i, j, k = torch.split(input, channels, dim=1)\n",
        "\n",
        "    # Apply ReLU only to real part, preserve imaginary parts\n",
        "    r_out = F.relu(r)\n",
        "\n",
        "    return torch.cat([r_out, i, j, k], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0d2992c5",
      "metadata": {
        "id": "0d2992c5"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# QUATERNION CNN MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class QuaternionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(QuaternionCNN, self).__init__()\n",
        "\n",
        "        # Input: RGB image -> Convert to quaternion (add zero imaginary component)\n",
        "        # CIFAR-10: 3x32x32 -> 4x32x32 (RGB + zero quaternion component)\n",
        "\n",
        "        # First conv layer: 4 -> 64 quaternion channels\n",
        "        self.conv1 = QuaternionConv2d(1, 16, kernel_size=3, padding=1)  # 4->64 channels\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
        "\n",
        "        # Second conv layer: 64 -> 128 quaternion channels\n",
        "        self.conv2 = QuaternionConv2d(16, 32, kernel_size=3, padding=1)  # 64->128 channels\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
        "\n",
        "        # Third conv layer: 128 -> 256 quaternion channels\n",
        "        self.conv3 = QuaternionConv2d(32, 64, kernel_size=3, padding=1)  # 128->256 channels\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
        "\n",
        "        # Classifier: quaternion features -> real output\n",
        "        self.fc1 = QuaternionLinear(64 * 4 * 4, 512)  # Quaternion linear\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Final layer: quaternion -> real\n",
        "        self.fc2 = nn.Linear(4 * 512, num_classes)  # Real-valued output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convert RGB to quaternion: add zero component\n",
        "        batch_size = x.shape[0]\n",
        "        zero_component = torch.zeros(batch_size, 1, 32, 32, device=x.device)\n",
        "        x = torch.cat([x, zero_component], dim=1)  # [B, 4, 32, 32]\n",
        "\n",
        "        # Quaternion convolutions with ReLU activation\n",
        "        x = quaternion_relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = quaternion_relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = quaternion_relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Quaternion fully connected\n",
        "        x = quaternion_relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Final real-valued classification\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class QuaternionCNN_Light(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv quaternion layers ridotti\n",
        "        self.conv1 = QuaternionConv2d(1, 8, kernel_size=3, padding=1)    # 4->32 channels\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
        "\n",
        "        self.conv2 = QuaternionConv2d(8, 16, kernel_size=3, padding=1)   # 32->64 channels\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
        "\n",
        "        self.conv3 = QuaternionConv2d(16, 32, kernel_size=3, padding=1)  # 64->128 channels\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
        "\n",
        "        # Fully connected quaternion\n",
        "        self.fc1 = QuaternionLinear(32 * 4 * 4, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Output real-valued\n",
        "        self.fc2 = nn.Linear(4 * 128, num_classes)\n",
        "\n",
        "        # Inizializzazione con gain ridotto\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, QuaternionConv2d) or isinstance(m, QuaternionLinear):\n",
        "                with torch.no_grad():\n",
        "                    m.weight.copy_(quaternion_init(m.weight, gain=0.1))\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        zero_component = torch.zeros(batch_size, 1, 32, 32, device=x.device)\n",
        "        x = torch.cat([x, zero_component], dim=1)  # RGB + zero component\n",
        "\n",
        "        # Convolution + Split ReLU\n",
        "        x = quaternion_split_relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = quaternion_split_relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = quaternion_split_relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten + Fully connected quaternion\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = quaternion_split_relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output finale reale\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b86fd374",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "b86fd374",
        "outputId": "9c42956c-ed52-42cb-8612-d4ae21294c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio training della Quaternion CNN su CIFAR-10...\n",
            "Device: cuda\n",
            "Parametri del modello: 291,338\n",
            "Epoch [1/50], Step [100/391], Loss: 2.1118, Acc: 23.99%\n",
            "Epoch [1/50], Step [200/391], Loss: 1.8995, Acc: 28.39%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65934463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Avvia il training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_quaternion_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-65934463.py\u001b[0m in \u001b[0;36mtrain_quaternion_cnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_WELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TRAINING AND EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def train_quaternion_cnn():\n",
        "    # Data loading and preprocessing\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                          download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                         download=False, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                           shuffle=False, num_workers=2)\n",
        "\n",
        "    # Model, loss, optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = QuaternionCNN_Light().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "    print(\"Inizio training della Quaternion CNN su CIFAR-10...\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Parametri del modello: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], '\n",
        "                      f'Loss: {running_loss/100:.4f}, Acc: {100*correct/total:.2f}%')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation ogni 5 epoch\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            model.eval()\n",
        "            test_correct = 0\n",
        "            test_total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    test_total += labels.size(0)\n",
        "                    test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}] - Test Accuracy: {100*test_correct/test_total:.2f}%')\n",
        "\n",
        "    print(\"Training completato!\")\n",
        "\n",
        "    # Test finale\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuratezza finale su test set: {100*correct/total:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Avvia il training\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_quaternion_cnn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed789473",
      "metadata": {
        "id": "ed789473"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Trasformazioni test\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "# Dataset di test\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Mappa delle classi CIFAR-10\n",
        "classes = ('airplane','automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Variabili per calcolare accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy sul test set: {accuracy:.2f}%')\n",
        "\n",
        "# Visualizziamo alcune immagini a caso con predizione\n",
        "num_show = 5\n",
        "for _ in range(num_show):\n",
        "    idx = np.random.randint(0, len(testset))\n",
        "    image, label = testset[idx]\n",
        "\n",
        "    # Mostriamo immagine denormalizzata\n",
        "    image_display = image * 0.5 + 0.5\n",
        "    plt.imshow(np.transpose(image_display.numpy(), (1, 2, 0)))\n",
        "    plt.title(f'Label reale: {classes[label]}')\n",
        "    plt.show()\n",
        "\n",
        "    # Predizione\n",
        "    input_img = image.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_img)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "    print(f'Predizione del modello: {classes[predicted.item()]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc24be6",
      "metadata": {
        "id": "afc24be6"
      },
      "outputs": [],
      "source": [
        "# dopo il training\n",
        "torch.save(model.state_dict(), \"quaternion_cnn.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552db2ab",
      "metadata": {
        "id": "552db2ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}